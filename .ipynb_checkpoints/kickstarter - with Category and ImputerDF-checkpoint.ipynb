{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization Libraies\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in the Dataset \n",
    "source: https://www.kaggle.com/kemical/kickstarter-projects/notebooks?sortBy=dateRun&group=upvoted&pageSize=20&datasetId=4104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>goal</th>\n",
       "      <th>launched</th>\n",
       "      <th>pledged</th>\n",
       "      <th>state</th>\n",
       "      <th>backers</th>\n",
       "      <th>country</th>\n",
       "      <th>usd pledged</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <th>usd_goal_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002330</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2015-08-11 12:12:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1533.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000003930</td>\n",
       "      <td>Greeting From Earth: ZGAC Arts Capsule For ET</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>2017-09-02 04:43:57</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>15</td>\n",
       "      <td>US</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>30000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000004038</td>\n",
       "      <td>Where is Hank?</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>2013-01-12 00:20:50</td>\n",
       "      <td>220.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>45000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000007540</td>\n",
       "      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2012-03-17 03:24:11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000011046</td>\n",
       "      <td>Community Film Project: The Art of Neighborhoo...</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-08-29</td>\n",
       "      <td>19500.0</td>\n",
       "      <td>2015-07-04 08:35:03</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>canceled</td>\n",
       "      <td>14</td>\n",
       "      <td>US</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>19500.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               name  \\\n",
       "0  1000002330                    The Songs of Adelaide & Abullah   \n",
       "1  1000003930      Greeting From Earth: ZGAC Arts Capsule For ET   \n",
       "2  1000004038                                     Where is Hank?   \n",
       "3  1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n",
       "4  1000011046  Community Film Project: The Art of Neighborhoo...   \n",
       "\n",
       "         category main_category currency   deadline     goal  \\\n",
       "0          Poetry    Publishing      GBP 2015-10-09   1000.0   \n",
       "1  Narrative Film  Film & Video      USD 2017-11-01  30000.0   \n",
       "2  Narrative Film  Film & Video      USD 2013-02-26  45000.0   \n",
       "3           Music         Music      USD 2012-04-16   5000.0   \n",
       "4    Film & Video  Film & Video      USD 2015-08-29  19500.0   \n",
       "\n",
       "             launched  pledged     state  backers country  usd pledged  \\\n",
       "0 2015-08-11 12:12:28      0.0    failed        0      GB          0.0   \n",
       "1 2017-09-02 04:43:57   2421.0    failed       15      US        100.0   \n",
       "2 2013-01-12 00:20:50    220.0    failed        3      US        220.0   \n",
       "3 2012-03-17 03:24:11      1.0    failed        1      US          1.0   \n",
       "4 2015-07-04 08:35:03   1283.0  canceled       14      US       1283.0   \n",
       "\n",
       "   usd_pledged_real  usd_goal_real  \n",
       "0               0.0        1533.95  \n",
       "1            2421.0       30000.00  \n",
       "2             220.0       45000.00  \n",
       "3               1.0        5000.00  \n",
       "4            1283.0       19500.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To view all the columns \n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df = pd.read_csv('kickstarter.csv', \n",
    "                parse_dates=['deadline', 'launched'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "- delete ID\n",
    "- feature engineering (deadline and launched)\n",
    "- Consider top five countries\n",
    "- Only consider failed or successful and make it a binary classifictaion\n",
    "- Will keep all the 15 main categories\n",
    "- For category we could pass it to the ordinal encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total NAN</th>\n",
       "      <th>Percentage of NAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>usd pledged</th>\n",
       "      <td>3797</td>\n",
       "      <td>1.002744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>4</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usd_goal_real</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backers</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pledged</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>launched</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goal</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deadline</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Total NAN  Percentage of NAN\n",
       "usd pledged            3797           1.002744\n",
       "name                      4           0.001056\n",
       "usd_goal_real             0           0.000000\n",
       "usd_pledged_real          0           0.000000\n",
       "country                   0           0.000000\n",
       "backers                   0           0.000000\n",
       "state                     0           0.000000\n",
       "pledged                   0           0.000000\n",
       "launched                  0           0.000000\n",
       "goal                      0           0.000000\n",
       "deadline                  0           0.000000\n",
       "currency                  0           0.000000\n",
       "main_category             0           0.000000\n",
       "category                  0           0.000000\n",
       "ID                        0           0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_nan = df.isna().sum().sort_values(ascending=False)\n",
    "percentage_nan = (total_nan / df.shape[0]) * 100\n",
    "tabel = pd.concat([total_nan, percentage_nan], axis=1, keys=['Total NAN', 'Percentage of NAN'])\n",
    "tabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "failed        197719\n",
       "successful    133956\n",
       "canceled       38779\n",
       "undefined       3562\n",
       "live            2799\n",
       "suspended       1846\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "failed        197719\n",
       "successful    133956\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering out the dataset for binary target variable - failed / successful\n",
    "df = df.loc[(df['state'] == 'failed') | (df['state'] == 'successful')]\n",
    "df.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4053816580908309"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imbalance classification but not worrisome\n",
    "successful = 131490/(192871+131490)\n",
    "successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    197719\n",
       "1    133956\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the target variable to 0 and 1 \n",
    "df['state'] = df['state'].map({'failed':0, 'successful':1})\n",
    "df['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    197713\n",
       "1         5\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['usd_pledged_real'] < df['usd_goal_real']]['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    67142\n",
       "0     9151\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for backers\n",
    "df.loc[df['backers'] > 70]['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19463\n",
       "0     1374\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['usd_pledged_real'] > 25000]['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20837, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['usd_pledged_real'] > 25000].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is clearly a data leakage here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting verticals that we don't need \n",
    "- Dropping USD pledged and pledged as usd_pledged_real has the same information\n",
    "- Dropping country as currency and country are highly correlated\n",
    "- Dropping goal as we have goal converted in USD as a vertical\n",
    "- Dropping backers and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331675, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['usd pledged', 'pledged', 'country', 'goal', 'ID', 'usd_pledged_real', 'backers'], axis=1) \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping 4 nan values in name\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 331672 entries, 0 to 378660\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   name           331672 non-null  object        \n",
      " 1   category       331672 non-null  object        \n",
      " 2   main_category  331672 non-null  object        \n",
      " 3   currency       331672 non-null  object        \n",
      " 4   deadline       331672 non-null  datetime64[ns]\n",
      " 5   launched       331672 non-null  datetime64[ns]\n",
      " 6   state          331672 non-null  int64         \n",
      " 7   usd_goal_real  331672 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(1), int64(1), object(4)\n",
      "memory usage: 22.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking high cardinality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category has 159 unique values\n",
      "main_category has 15 unique values\n",
      "currency has 14 unique values\n"
     ]
    }
   ],
   "source": [
    "cols = ['category', 'main_category', 'currency']\n",
    "\n",
    "for col in cols:\n",
    "    print(f\"{col} has {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product Design     18680\n",
       "Documentary        14523\n",
       "Music              12633\n",
       "Tabletop Games     11744\n",
       "Shorts             11394\n",
       "                   ...  \n",
       "Residencies           68\n",
       "Letterpress           46\n",
       "Chiptune              33\n",
       "Literary Spaces       19\n",
       "Taxidermy             10\n",
       "Name: category, Length: 159, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Either we can delete category vertical or ordinal encode it!\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USD    261509\n",
       "GBP     29475\n",
       "EUR     14378\n",
       "CAD     12375\n",
       "AUD      6621\n",
       "SEK      1510\n",
       "MXN      1411\n",
       "NZD      1274\n",
       "DKK       929\n",
       "CHF       652\n",
       "NOK       584\n",
       "HKD       477\n",
       "SGD       454\n",
       "JPY        23\n",
       "Name: currency, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets consider top 5 currencies and delete the rest \n",
    "df.currency.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out top 5 currencies \n",
    "df = df.loc[(df['currency'] == 'USD') | (df['currency'] == 'GBP') | (df['currency'] == 'EUR') \\\n",
    "      | (df['currency'] == 'CAD') | (df['currency'] == 'AUD')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA          261509\n",
       "UK            29475\n",
       "Europe        14378\n",
       "Canada        12375\n",
       "Australia      6621\n",
       "Name: currency, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the currency names into countries so it will be easier to ask a user for input\n",
    "df['currency'] = df['currency'].map({\n",
    "                'USD':'USA',\n",
    "                'GBP':'UK',\n",
    "                'EUR':'Europe',\n",
    "                'CAD':'Canada',\n",
    "                'AUD': 'Australia'})\n",
    "df.currency.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index as we deleted a few rows when we filtered\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering \n",
    "- calculating the length of the campaign from deadline and launched \n",
    "- calculating the total number of words in name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a new column length_days\n",
    "df['length_days'] = (df['deadline'] - df['launched']).dt.days + 1\n",
    "\n",
    "# deleting deadline and launched cols\n",
    "df = df.drop(['deadline', 'launched'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of words in each row in name\n",
    "df['name'] = df['name'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5946183419091691"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need our model to beat this score\n",
    "baseline = 1 - successful\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Matrix and Target Variable\n",
    "X = df.drop('state', axis=1)\n",
    "y = df['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test dataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259486, 6)\n",
      "(64872, 6)\n",
      "(259486,)\n",
      "(64872,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>usd_goal_real</th>\n",
       "      <th>length_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87131</th>\n",
       "      <td>3</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181947</th>\n",
       "      <td>3</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Canada</td>\n",
       "      <td>47824.01</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86969</th>\n",
       "      <td>11</td>\n",
       "      <td>Art</td>\n",
       "      <td>Art</td>\n",
       "      <td>USA</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149100</th>\n",
       "      <td>3</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2816.37</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114517</th>\n",
       "      <td>1</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>UK</td>\n",
       "      <td>32037.42</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name     category main_category   currency  usd_goal_real  length_days\n",
       "87131      3   Technology    Technology        USA        8000.00           20\n",
       "181947     3  Documentary  Film & Video     Canada       47824.01           15\n",
       "86969     11          Art           Art        USA       25000.00           31\n",
       "149100     3   Nonfiction    Publishing  Australia        2816.37           35\n",
       "114517     1  Documentary  Film & Video         UK       32037.42           41"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'usd_goal_real', 'length_days'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at numerical attributes for simple imputer with median \n",
    "num_attribs = X_train.select_dtypes(exclude='object')\n",
    "num_attribs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'main_category', 'currency'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at categorical attributes for simple imputer with 'most_frequent'\n",
    "cat_attribs = X_train.select_dtypes(include='object')\n",
    "cat_attribs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['main_category', 'currency'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making seperate list of cols for ohe and ordinal encoding\n",
    "cat_attribs_ohe = X_train[['main_category', 'currency']]\n",
    "cat_attribs_ohe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_attribs_ord = X_train[['category']]\n",
    "cat_attribs_ord.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Building a custom Transformer that will give the output in a dataframe after \n",
    "applying the simple imputer so we could pass it to the categorical_encoders \n",
    "which does not accept np.array\"\"\" \n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ImputerDF(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.imputer = SimpleImputer(strategy='most_frequent')\n",
    "        self.cols = []\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.imputer.fit(X)\n",
    "        self.cols = list(X.columns)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_t = self.imputer.transform(X)\n",
    "        return pd.DataFrame(X_t, columns=self.cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from category_encoders import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using median as the strategy for Simple Imputer to predict NaN values considering the ouliers in the data\n",
    "num_pipeline = make_pipeline(\n",
    "                            SimpleImputer(strategy='median'),\n",
    "                            StandardScaler()\n",
    ")\n",
    "# Adding the Custom Transformer to impute using 'most_frequent' strategy and giving out an output as a dataframe instead of an array\n",
    "cat_pipeline = make_pipeline(\n",
    "                            ImputerDF(),\n",
    "                            OrdinalEncoder(cols = cat_attribs_ord),\n",
    "                            OneHotEncoder(cols = cat_attribs_ohe)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a list of categorical and numerical columns to pass it in the column transformer\n",
    "cat_attributes = list(cat_attribs)\n",
    "num_attributes = list(num_attribs)\n",
    "\n",
    "# putting two pipelines together using ColumnTransformer\n",
    "final_pipeline = ColumnTransformer([\n",
    "                            ('num_pipeline', num_pipeline, num_attributes),\n",
    "                            ('cat_pipeline', cat_pipeline, cat_attributes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and trasnform on X_train\n",
    "X_train_transformed = final_pipeline.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259486, 24)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "- Ran a few simple models and pick the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770230378517531"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_jobs=-1, \n",
    "                                    random_state=105, \n",
    "                                    n_estimators=70, \n",
    "                                    max_depth=11)\n",
    "\n",
    "forest_clf.fit(X_train_transformed,y_train)\n",
    "\n",
    "y_pred_train = forest_clf.predict(X_train_transformed)\n",
    "\n",
    "score = accuracy_score(y_train, y_pred_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6688530477066071"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(forest_clf,\n",
    "                         X_train_transformed,\n",
    "                         y_train,\n",
    "                         scoring='roc_auc',\n",
    "                         cv=4,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.87      0.76    154209\n",
      "           1       0.67      0.40      0.50    105277\n",
      "\n",
      "    accuracy                           0.68    259486\n",
      "   macro avg       0.68      0.63      0.63    259486\n",
      "weighted avg       0.68      0.68      0.66    259486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6327091086595448\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6494647110056034"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "\n",
    "lr.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_train = lr.predict(X_train_transformed)\n",
    "\n",
    "score = accuracy_score(y_train, y_pred_train)\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.649403049407622"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(lr,\n",
    "                         X_train_transformed,\n",
    "                         y_train,\n",
    "                         scoring='roc_auc',\n",
    "                         cv=4,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.81      0.73    154209\n",
      "           1       0.60      0.42      0.49    105277\n",
      "\n",
      "    accuracy                           0.65    259486\n",
      "   macro avg       0.63      0.61      0.61    259486\n",
      "weighted avg       0.64      0.65      0.63    259486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6126350445538685\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6755085052758145"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "gb.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_train = gb.predict(X_train_transformed)\n",
    "\n",
    "score = accuracy_score(y_train, y_pred_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6753505257353362"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(gb,\n",
    "                         X_train_transformed,\n",
    "                         y_train,\n",
    "                         scoring='roc_auc',\n",
    "                         cv=7)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6114125617567037"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(n_jobs=-1)\n",
    "\n",
    "sgd.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_train = sgd.predict(X_train_transformed)\n",
    "\n",
    "score = accuracy_score(y_train, y_pred_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6282805096439829"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(sgd,\n",
    "                         X_train_transformed,\n",
    "                         y_train,\n",
    "                         scoring='roc_auc',\n",
    "                         cv=4)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifiers using soft voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_jobs=-1, \n",
    "                                    random_state=105, \n",
    "                                    n_estimators=60, \n",
    "                                    max_depth=10)\n",
    "# svm = SVC(random_state=105, \n",
    "#                 gamma='auto',\n",
    "#          probability=True) \n",
    "\n",
    "sgd = SGDClassifier(loss=\"modified_huber\", \n",
    "                   n_jobs=-1)\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "                estimators=[(\"lr\",lr), (\"rf\",forest_clf), \n",
    "                            (\"sgd\",sgd), (\"gb\", gb)],\n",
    "                voting='soft',\n",
    "                n_jobs=-1)\n",
    "\n",
    "voting_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_train = voting_clf.predict(X_train_transformed)\n",
    "\n",
    "score = accuracy_score(y_train, y_pred_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(voting_clf,\n",
    "                         X_train_transformed,\n",
    "                         y_train,\n",
    "                         scoring='roc_auc',\n",
    "                         cv=4,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier using hard voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_jobs=-1, \n",
    "                                    random_state=105,\n",
    "                                    max_depth=15)\n",
    "\n",
    "sgd = SGDClassifier(n_jobs=-1) \n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "voting_clf_hard = VotingClassifier(\n",
    "                estimators=[(\"lr\",lr), (\"rf\",forest_clf), \n",
    "                            (\"sgd\",sgd), (\"gb\", gb)],\n",
    "                voting='hard',\n",
    "                n_jobs=-1)\n",
    "\n",
    "voting_clf_hard.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_train = voting_clf_hard.predict(X_train_transformed)\n",
    "\n",
    "score = accuracy_score(y_train, y_pred_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(voting_clf_hard,\n",
    "                         X_train_transformed,\n",
    "                         y_train,\n",
    "                         scoring='roc_auc',\n",
    "                         cv=4,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the most generalized model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating our model on Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_transformed = final_pipeline.transform(X_test)\n",
    "\n",
    "# y_test_pred = forest_clf.predict(X_test_transformed)\n",
    "\n",
    "# score = accuracy_score(y_test, y_test_pred)\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
