{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization Libraies\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in the Dataset \n",
    "source: https://www.kaggle.com/kemical/kickstarter-projects/notebooks?sortBy=dateRun&group=upvoted&pageSize=20&datasetId=4104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>goal</th>\n",
       "      <th>launched</th>\n",
       "      <th>pledged</th>\n",
       "      <th>state</th>\n",
       "      <th>backers</th>\n",
       "      <th>country</th>\n",
       "      <th>usd pledged</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <th>usd_goal_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002330</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2015-08-11 12:12:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1533.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000003930</td>\n",
       "      <td>Greeting From Earth: ZGAC Arts Capsule For ET</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>2017-09-02 04:43:57</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>15</td>\n",
       "      <td>US</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>30000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000004038</td>\n",
       "      <td>Where is Hank?</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>2013-01-12 00:20:50</td>\n",
       "      <td>220.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>45000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000007540</td>\n",
       "      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2012-03-17 03:24:11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000011046</td>\n",
       "      <td>Community Film Project: The Art of Neighborhoo...</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-08-29</td>\n",
       "      <td>19500.0</td>\n",
       "      <td>2015-07-04 08:35:03</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>canceled</td>\n",
       "      <td>14</td>\n",
       "      <td>US</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>19500.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               name  \\\n",
       "0  1000002330                    The Songs of Adelaide & Abullah   \n",
       "1  1000003930      Greeting From Earth: ZGAC Arts Capsule For ET   \n",
       "2  1000004038                                     Where is Hank?   \n",
       "3  1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n",
       "4  1000011046  Community Film Project: The Art of Neighborhoo...   \n",
       "\n",
       "         category main_category currency   deadline     goal  \\\n",
       "0          Poetry    Publishing      GBP 2015-10-09   1000.0   \n",
       "1  Narrative Film  Film & Video      USD 2017-11-01  30000.0   \n",
       "2  Narrative Film  Film & Video      USD 2013-02-26  45000.0   \n",
       "3           Music         Music      USD 2012-04-16   5000.0   \n",
       "4    Film & Video  Film & Video      USD 2015-08-29  19500.0   \n",
       "\n",
       "             launched  pledged     state  backers country  usd pledged  \\\n",
       "0 2015-08-11 12:12:28      0.0    failed        0      GB          0.0   \n",
       "1 2017-09-02 04:43:57   2421.0    failed       15      US        100.0   \n",
       "2 2013-01-12 00:20:50    220.0    failed        3      US        220.0   \n",
       "3 2012-03-17 03:24:11      1.0    failed        1      US          1.0   \n",
       "4 2015-07-04 08:35:03   1283.0  canceled       14      US       1283.0   \n",
       "\n",
       "   usd_pledged_real  usd_goal_real  \n",
       "0               0.0        1533.95  \n",
       "1            2421.0       30000.00  \n",
       "2             220.0       45000.00  \n",
       "3               1.0        5000.00  \n",
       "4            1283.0       19500.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To view all the columns \n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df = pd.read_csv('kickstarter.csv', \n",
    "                parse_dates=['deadline', 'launched'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "- delete ID\n",
    "- feature engineering (deadline and launched)\n",
    "- Consider top five countries\n",
    "- Only consider failed or successful and make it a binary classifictaion\n",
    "- Will keep all the 15 main categories\n",
    "- For category we could pass it to the ordinal encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total NAN</th>\n",
       "      <th>Percentage of NAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>usd pledged</th>\n",
       "      <td>3797</td>\n",
       "      <td>1.002744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>4</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usd_goal_real</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backers</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pledged</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>launched</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goal</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deadline</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Total NAN  Percentage of NAN\n",
       "usd pledged            3797           1.002744\n",
       "name                      4           0.001056\n",
       "usd_goal_real             0           0.000000\n",
       "usd_pledged_real          0           0.000000\n",
       "country                   0           0.000000\n",
       "backers                   0           0.000000\n",
       "state                     0           0.000000\n",
       "pledged                   0           0.000000\n",
       "launched                  0           0.000000\n",
       "goal                      0           0.000000\n",
       "deadline                  0           0.000000\n",
       "currency                  0           0.000000\n",
       "main_category             0           0.000000\n",
       "category                  0           0.000000\n",
       "ID                        0           0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_nan = df.isna().sum().sort_values(ascending=False)\n",
    "percentage_nan = (total_nan / df.shape[0]) * 100\n",
    "tabel = pd.concat([total_nan, percentage_nan], axis=1, keys=['Total NAN', 'Percentage of NAN'])\n",
    "tabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "failed        197719\n",
       "successful    133956\n",
       "canceled       38779\n",
       "undefined       3562\n",
       "live            2799\n",
       "suspended       1846\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "failed        197719\n",
       "successful    133956\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering out the dataset for binary target variable - failed / successful\n",
    "df = df.loc[(df['state'] == 'failed') | (df['state'] == 'successful')]\n",
    "df.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4053816580908309"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imbalance classification but not worrisome\n",
    "successful = 131490/(192871+131490)\n",
    "successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    197719\n",
       "1    133956\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the target variable to 0 and 1 \n",
    "df['state'] = df['state'].map({'failed':0, 'successful':1})\n",
    "df['state'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    197713\n",
       "1         5\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['usd_pledged_real'] < df['usd_goal_real']]['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    67142\n",
       "0     9151\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for backers\n",
    "df.loc[df['backers'] > 70]['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19463\n",
       "0     1374\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['usd_pledged_real'] > 25000]['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20837, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['usd_pledged_real'] > 25000].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is clearly a data leakage here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting verticals that we don't need \n",
    "- Dropping USD pledged and pledged as usd_pledged_real has the same information\n",
    "- Dropping country as currency and country are highly correlated\n",
    "- Dropping goal as we have goal converted in USD as a vertical\n",
    "- Dropping backers and usd_pledged_real due to data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331675, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['usd pledged', 'pledged', 'country', 'goal', 'ID', 'usd_pledged_real','backers'], axis=1) \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping 4 nan values in name\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 331672 entries, 0 to 378660\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   name           331672 non-null  object        \n",
      " 1   category       331672 non-null  object        \n",
      " 2   main_category  331672 non-null  object        \n",
      " 3   currency       331672 non-null  object        \n",
      " 4   deadline       331672 non-null  datetime64[ns]\n",
      " 5   launched       331672 non-null  datetime64[ns]\n",
      " 6   state          331672 non-null  int64         \n",
      " 7   usd_goal_real  331672 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(1), int64(1), object(4)\n",
      "memory usage: 22.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking high cardinality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category has 159 unique values\n",
      "main_category has 15 unique values\n",
      "currency has 14 unique values\n"
     ]
    }
   ],
   "source": [
    "cols = ['category', 'main_category', 'currency']\n",
    "\n",
    "for col in cols:\n",
    "    print(f\"{col} has {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product Design     18680\n",
       "Documentary        14523\n",
       "Music              12633\n",
       "Tabletop Games     11744\n",
       "Shorts             11394\n",
       "                   ...  \n",
       "Residencies           68\n",
       "Letterpress           46\n",
       "Chiptune              33\n",
       "Literary Spaces       19\n",
       "Taxidermy             10\n",
       "Name: category, Length: 159, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Either we can delete category vertical or ordinal encode it!\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping category \n",
    "df.drop('category', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USD    261509\n",
       "GBP     29475\n",
       "EUR     14378\n",
       "CAD     12375\n",
       "AUD      6621\n",
       "SEK      1510\n",
       "MXN      1411\n",
       "NZD      1274\n",
       "DKK       929\n",
       "CHF       652\n",
       "NOK       584\n",
       "HKD       477\n",
       "SGD       454\n",
       "JPY        23\n",
       "Name: currency, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets consider top 5 currencies and delete the rest \n",
    "df.currency.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out top 5 currencies \n",
    "df = df.loc[(df['currency'] == 'USD') | (df['currency'] == 'GBP') | (df['currency'] == 'EUR') \\\n",
    "      | (df['currency'] == 'CAD') | (df['currency'] == 'AUD')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA          261509\n",
       "UK            29475\n",
       "Europe        14378\n",
       "Canada        12375\n",
       "Australia      6621\n",
       "Name: currency, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the currency names into countries so it will be easier to ask a user for input\n",
    "df['currency'] = df['currency'].map({\n",
    "                'USD':'USA',\n",
    "                'GBP':'UK',\n",
    "                'EUR':'Europe',\n",
    "                'CAD':'Canada',\n",
    "                'AUD': 'Australia'})\n",
    "df.currency.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index as we deleted a few rows when we filtered\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering \n",
    "- calculating the length of the campaign from deadline and launched \n",
    "- calculating the total number of words in name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a new column length_days\n",
    "df['length_days'] = (df['deadline'] - df['launched']).dt.days + 1\n",
    "\n",
    "# deleting deadline and launched cols\n",
    "df = df.drop(['deadline', 'launched'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of words in each row in name\n",
    "df['name'] = df['name'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5946183419091691"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need our model to beat this score\n",
    "baseline = 1 - successful\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Matrix and Target Variable\n",
    "X = df.drop('state', axis=1)\n",
    "y = df['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test dataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259486, 5)\n",
      "(64872, 5)\n",
      "(259486,)\n",
      "(64872,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>usd_goal_real</th>\n",
       "      <th>length_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87131</th>\n",
       "      <td>3</td>\n",
       "      <td>Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181947</th>\n",
       "      <td>3</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Canada</td>\n",
       "      <td>47824.01</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86969</th>\n",
       "      <td>11</td>\n",
       "      <td>Art</td>\n",
       "      <td>USA</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149100</th>\n",
       "      <td>3</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2816.37</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114517</th>\n",
       "      <td>1</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>UK</td>\n",
       "      <td>32037.42</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name main_category   currency  usd_goal_real  length_days\n",
       "87131      3    Technology        USA        8000.00           20\n",
       "181947     3  Film & Video     Canada       47824.01           15\n",
       "86969     11           Art        USA       25000.00           31\n",
       "149100     3    Publishing  Australia        2816.37           35\n",
       "114517     1  Film & Video         UK       32037.42           41"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'usd_goal_real', 'length_days'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at numerical attributes for simple imputer with median \n",
    "num_attribs = X_train.select_dtypes(exclude='object')\n",
    "num_attribs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['main_category', 'currency'], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at categorical attributes for simple imputer with 'most_frequent'\n",
    "cat_attribs = X_train.select_dtypes(include='object')\n",
    "cat_attribs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using median as the strategy for Simple Imputer to predict NaN values considering the ouliers in the data\n",
    "num_pipeline = make_pipeline(\n",
    "                            SimpleImputer(strategy='median'),\n",
    "                            StandardScaler()\n",
    ")\n",
    "# Adding the Custom Transformer to impute using 'most_frequent' strategy and giving out an output as a dataframe instead of an array\n",
    "cat_pipeline = make_pipeline(\n",
    "                            SimpleImputer(strategy='most_frequent'),\n",
    "                            OneHotEncoder(handle_unknown='ignore')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a list of categorical and numerical columns to pass it in the column transformer\n",
    "cat_attributes = list(cat_attribs)\n",
    "num_attributes = list(num_attribs)\n",
    "\n",
    "# putting two pipelines together using ColumnTransformer\n",
    "final_pipeline = ColumnTransformer([\n",
    "                            ('num_pipeline', num_pipeline, num_attributes),\n",
    "                            ('cat_pipeline', cat_pipeline, cat_attributes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and trasnform on X_train\n",
    "X_train_transformed = final_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259486, 23)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "- Ran a few simple models and pick the most generalized model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_jobs=-1, \n",
    "                                    random_state=105, \n",
    "                                    n_estimators=70, \n",
    "                                    max_depth=11)\n",
    "\n",
    "forest_clf.fit(X_train_transformed,y_train)\n",
    "\n",
    "y_pred_train = forest_clf.predict(X_train_transformed)\n",
    "\n",
    "score = accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(forest_clf,\n",
    "                         X_train_transformed,\n",
    "                         y_train,\n",
    "                         scoring='roc_auc',\n",
    "                         cv=4,\n",
    "                         n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy score on training set: 0.6687913798817663\n",
      "\n",
      "\n",
      "    ROC AUC score on training set: 0.6259235959391961\n",
      "\n",
      "    ROC AUC score on validation set: 0.7117164347862533\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "    Accuracy score on training set: {score}\\n\\n\n",
    "    ROC AUC score on training set: {roc_auc_score(y_train, y_pred_train)}\\n\n",
    "    ROC AUC score on validation set: {scores.mean()}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.85      0.75    154209\n",
      "           1       0.65      0.40      0.49    105277\n",
      "\n",
      "    accuracy                           0.67    259486\n",
      "   macro avg       0.66      0.63      0.62    259486\n",
      "weighted avg       0.66      0.67      0.65    259486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "\n",
    "lr.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_train = lr.predict(X_train_transformed)\n",
    "\n",
    "score = accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(lr,\n",
    "                         X_train_transformed,\n",
    "                         y_train,\n",
    "                         scoring='roc_auc',\n",
    "                         cv=4,\n",
    "                         n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy score on training set: 0.6488018621428516\n",
      "\n",
      "\n",
      "    ROC AUC score on training set: 0.6119010382152981\n",
      "\n",
      "    ROC AUC score on validation set: 0.6862637607295743\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "    Accuracy score on training set: {score}\\n\\n\n",
    "    ROC AUC score on training set: {roc_auc_score(y_train, y_pred_train)}\\n\n",
    "    ROC AUC score on validation set: {scores.mean()}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.81      0.73    154209\n",
      "           1       0.60      0.42      0.49    105277\n",
      "\n",
      "    accuracy                           0.65    259486\n",
      "   macro avg       0.63      0.61      0.61    259486\n",
      "weighted avg       0.64      0.65      0.63    259486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "gb.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_train = gb.predict(X_train_transformed)\n",
    "\n",
    "score = accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(gb,\n",
    "                         X_train_transformed,\n",
    "                         y_train,\n",
    "                         scoring='roc_auc',\n",
    "                         cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy score on training set: 0.6691690495826365\n",
      "\n",
      "\n",
      "    ROC AUC score on training set: 0.6359917824000834\n",
      "\n",
      "    ROC AUC score on validation set: 0.7190563452906739\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "    Accuracy score on training set: {score}\\n\\n\n",
    "    ROC AUC score on training set: {roc_auc_score(y_train, y_pred_train)}\\n\n",
    "    ROC AUC score on validation set: {scores.mean()}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.74    154209\n",
      "           1       0.63      0.46      0.53    105277\n",
      "\n",
      "    accuracy                           0.67    259486\n",
      "   macro avg       0.66      0.64      0.64    259486\n",
      "weighted avg       0.66      0.67      0.66    259486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(n_jobs=-1)\n",
    "\n",
    "sgd.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_train = sgd.predict(X_train_transformed)\n",
    "\n",
    "score = accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(sgd,\n",
    "                         X_train_transformed,\n",
    "                         y_train,\n",
    "                         scoring='roc_auc',\n",
    "                         cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy score on training set: 0.6205999552962395\n",
      "\n",
      "\n",
      "    ROC AUC score on training set: 0.5686696138187086\n",
      "\n",
      "    ROC AUC score on validation set: 0.6690354473135515\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "    Accuracy score on training set: {score}\\n\\n\n",
    "    ROC AUC score on training set: {roc_auc_score(y_train, y_pred_train)}\\n\n",
    "    ROC AUC score on validation set: {scores.mean()}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.84      0.73    154209\n",
      "           1       0.56      0.29      0.39    105277\n",
      "\n",
      "    accuracy                           0.62    259486\n",
      "   macro avg       0.60      0.57      0.56    259486\n",
      "weighted avg       0.61      0.62      0.59    259486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifiers using soft voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_jobs=-1, \n",
    "                                    random_state=105, \n",
    "                                    n_estimators=60, \n",
    "                                    max_depth=10)\n",
    "\n",
    "sgd = SGDClassifier(loss=\"modified_huber\", \n",
    "                   n_jobs=-1)\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "                estimators=[(\"lr\",lr), (\"rf\",forest_clf), \n",
    "                            (\"sgd\",sgd), (\"gb\", gb)],\n",
    "                voting='soft',\n",
    "                n_jobs=-1)\n",
    "\n",
    "voting_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_train = voting_clf.predict(X_train_transformed)\n",
    "\n",
    "score = accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(voting_clf,\n",
    "                         X_train_transformed,\n",
    "                         y_train,\n",
    "                         scoring='roc_auc',\n",
    "                         cv=4,\n",
    "                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy score on training set: 0.6617967828707522\n",
      "\n",
      "\n",
      "    ROC AUC score on training set: 0.6210906271437819\n",
      "\n",
      "    ROC AUC score on validation set: 0.7079203924056413\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "    Accuracy score on training set: {score}\\n\\n\n",
    "    ROC AUC score on training set: {roc_auc_score(y_train, y_pred_train)}\\n\n",
    "    ROC AUC score on validation set: {scores.mean()}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.84      0.75    154209\n",
      "           1       0.63      0.41      0.49    105277\n",
      "\n",
      "    accuracy                           0.66    259486\n",
      "   macro avg       0.65      0.62      0.62    259486\n",
      "weighted avg       0.66      0.66      0.64    259486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier using hard voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_jobs=-1, \n",
    "                                    random_state=105,\n",
    "                                    max_depth=15)\n",
    "\n",
    "sgd = SGDClassifier(n_jobs=-1) \n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "voting_clf_hard = VotingClassifier(\n",
    "                estimators=[(\"lr\",lr), (\"rf\",forest_clf), \n",
    "                            (\"sgd\",sgd), (\"gb\", gb)],\n",
    "                voting='hard',\n",
    "                n_jobs=-1)\n",
    "\n",
    "voting_clf_hard.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred_train = voting_clf_hard.predict(X_train_transformed)\n",
    "\n",
    "score = accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when voting='hard'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 307, in _score\n    y_pred = method_caller(clf, \"decision_function\", X)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 53, in _cached_call\n    return getattr(estimator, method)(*args, **kwargs)\nAttributeError: 'VotingClassifier' object has no attribute 'decision_function'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in __call__\n    return [func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 252, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 560, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 607, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n    score = scorer._score(cached_call, estimator,\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 314, in _score\n    y_pred = method_caller(clf, \"predict_proba\", X)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 53, in _cached_call\n    return getattr(estimator, method)(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_voting.py\", line 321, in predict_proba\n    raise AttributeError(\"predict_proba is not available when\"\nAttributeError: predict_proba is not available when voting='hard'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-5714eb56dc2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m scores = cross_val_score(voting_clf_hard,\n\u001b[0m\u001b[1;32m      4\u001b[0m                          \u001b[0mX_train_transformed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 242\u001b[0;31m     scores = parallel(\n\u001b[0m\u001b[1;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when voting='hard'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(voting_clf_hard,\n",
    "                         X_train_transformed,\n",
    "                         y_train,\n",
    "                         scoring='roc_auc',\n",
    "                         cv=4,\n",
    "                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "    Accuracy score on training set: {score}\\n\\n\n",
    "    ROC AUC score on training set: {roc_auc_score(y_train, y_pred_train)}\\n\n",
    "    ROC AUC score on validation set: {scores.mean()}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the most generalized model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating our model on Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_transformed = final_pipeline.transform(X_test)\n",
    "\n",
    "# y_test_pred = forest_clf.predict(X_test_transformed)\n",
    "\n",
    "# score = accuracy_score(y_test, y_test_pred)\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
